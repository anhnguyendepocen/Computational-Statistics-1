{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is a drug effective or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug = [54, 73, 53, 70, 73, 68, 52, 65, 65] # treatment group\n",
    "placebo = [54, 51, 58, 44, 55, 52, 42, 47, 58, 46] # control group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "H_0 : \\mu_{drug} - \\mu_{placebo} = 0 \\\\\n",
    "H_1 : \\mu_{drug} - \\mu_{placebo} <> 0\n",
    "$$\n",
    "Where:\n",
    "\n",
    "$ H_0 $ -> **The null hypothesis:** there is no difference in the drug and placebo groups on average (the drug does not have any effect).\n",
    "\n",
    "$ H_1 $ -> **The alternative hypothesis:** there is a significant difference in the drug and placebo groups on average (the drug works).\n",
    "\n",
    "I will assume **type I error (alpha)** level at 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means difference of the samples\n",
    "np.mean(drug) - np.mean(placebo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the means difference statistically significant?\n",
    "\n",
    "We use **T-Student sampling distribution** and calculate **t-test** statistic to find out.\n",
    "\n",
    "**T-test** assumptions:\n",
    "1. Both groups (drug and placebo) should be normally distributed\n",
    "- Variances of the groups should be the same\n",
    "- Samples should be of the same size\n",
    "- At best there should be more than 20 observations in a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption 1\n",
    "Both groups (drug and placebo) should be normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(drug, color=\"skyblue\", label=\"Drug\", kde=True)\n",
    "sns.distplot(placebo, color=\"red\", label=\"Placebo\", kde=True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def normaltest(sample, name, alpha=0.05):\n",
    "    '''\n",
    "    Shapiro-Wilk test for samples with n < 50 observations.\n",
    "    Reference: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html\n",
    "    '''\n",
    "    W, p = stats.shapiro(sample)\n",
    "    #print(\"W = {:g}\".format(W))\n",
    "    #print(\"p = {:g}\".format(p))\n",
    "    if p < alpha:  # null hypothesis: sample comes from a normal distribution\n",
    "        print(\"{} does not come from a normal distribution\".format(name))\n",
    "    else:\n",
    "        print(\"{} comes from a normal distribution\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is drug normally distributed?\n",
    "normaltest(drug, \"Drug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is placebo normally distributed?\n",
    "normaltest(placebo, \"Placebo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To solve the issue of having too small sample size...\n",
    "# I could use the following:  (just joking!)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption 2\n",
    "Variances of the groups should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varsequals(sample1, sample2, alpha=0.01):\n",
    "    '''\n",
    "    Perform Bartlett’s test for equal variances.\n",
    "    Bartlett’s test tests the null hypothesis that all input samples are from populations with equal variances.\n",
    "    Reference: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.bartlett.html\n",
    "    ''' \n",
    "    T, p = stats.bartlett(sample1, sample2)\n",
    "    #print(\"T = {:g}\".format(T))\n",
    "    #print(\"p = {:g}\".format(p))\n",
    "    if p < alpha:  # null hypothesis: all input samples are from populations with equal variances\n",
    "        print(\"Not all input samples are from populations with equal variances.\")\n",
    "    else:\n",
    "        print(\"All input samples are from populations with equal variances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsequals(drug, placebo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate t-statistic\n",
    "Are our samples expected to have been drawn from the same population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p = stats.ttest_ind(drug, placebo) # all observations are independent\n",
    "print('t={:.4f}, p={:.4f}'.format(t_stat, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degrees of freedom\n",
    "df = len(drug) + len(placebo) - 2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the critical value (two-tailed test)\n",
    "# PPF (percent point function)\n",
    "cv = stats.t.ppf(1.0 - alpha/2, df)\n",
    "print(cv)\n",
    "\n",
    "# Confirm cv with CDF (cumulative distribution function)\n",
    "#p = stats.t.cdf(cv, df)\n",
    "#print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/t_table.jpeg\" width=\"70%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret via critical value (abs for symmetric distribution)\n",
    "if abs(t_stat) <= cv:\n",
    "    print('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "    print('Reject the null hypothesis that the means are equal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret via p-value\n",
    "if p > alpha:\n",
    "    print('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "    print('Reject the null hypothesis that the means are equal.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis test result\n",
    "We have sufficient evidence to reject **the null hypothesis** which means the drug works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Testing (Computational Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python's statitics module provides functions \n",
    "# for calculating mathematical statistics of numeric (real-valued) data\n",
    "from statistics import mean\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_diff = mean(drug) - mean(placebo)\n",
    "\n",
    "print(mean(drug))\n",
    "print(mean(placebo))\n",
    "\n",
    "print(f\"{observed_diff:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always visually inspect your data\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns # A library for statical plotting\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.distplot(drug, color=\"skyblue\", label=\"Drug\", kde=True);\n",
    "sns.distplot(placebo, color=\"red\", label=\"Placebo\", kde=True);\n",
    "plt.legend(); # Seaborn plots are interoperatable with matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would it look if there were no difference in the groups?\n",
    "#### That is the same if take the data and shuffled labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume there is no difference in means of the treatment and control group. If so, we can merge the observations from both groups and we can check how likely is that the observed_diff value or greater appears if there is no difference in the groups.\n",
    "\n",
    "Let's check how likely is for our observed_diff value or greater to exist when doing random groups assignment from the common pool many times. If the null hypothesis is true (the drug does not work, on average group means are close to 0) we should observe many occurences of mean differences equal or greater to observed_diff. If not, then we can safely reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unite the data\n",
    "combined = drug + placebo\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(combined) # Rearrange in-place\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly assign to drug and placebo group\n",
    "drug_random = combined[:len(drug)]\n",
    "placebo_random = combined[len(drug):]\n",
    "\n",
    "print(drug_random)\n",
    "print(placebo_random)\n",
    "\n",
    "sns.distplot(drug_random, color=\"skyblue\", label=\"Drug\", kde=True);\n",
    "sns.distplot(placebo_random, color=\"red\", label=\"Placebo\", kde=True);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate it a bunch of times\n",
    "n = 10_000\n",
    "count = 0\n",
    "simulated_means = []\n",
    "\n",
    "for _ in range(n):\n",
    "    shuffle(combined)\n",
    "    shuffled_diff = mean(combined[:len(drug)]) - mean(combined[len(drug):])\n",
    "    simulated_means.append(shuffled_diff)\n",
    "    count += (shuffled_diff >= observed_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"{n:,} label reshufflings produced only {count} instances \n",
    "with a difference at least as extreme as the observed difference of {observed_diff:.2f}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The p-value is a chance of observing the current difference when there is truly no difference\n",
    "p = count / n\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"alpha={}, p-value={}\".format(alpha,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret via p-value\n",
    "if p > alpha:\n",
    "    print('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "    print('Reject the null hypothesis that the means are equal.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/p_values.png\" width=\"30%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret visually\n",
    "\n",
    "# Find the quantile for the 2.5% cutoff\n",
    "cv = np.max(simulated_means) - stats.t.ppf(1.0 - alpha, df)\n",
    "\n",
    "simulated_means = np.asarray(simulated_means)\n",
    "sns.distplot(simulated_means, color=\"skyblue\", kde=True)\n",
    "plt.title(\"Simulated Differences of drug and placebo group means for the null hypothesis\", fontsize=12)\n",
    "plt.xlabel(\"Probability Means Difference\", fontsize=12)\n",
    "plt.ylabel(\"Percent\", fontsize=12)\n",
    "plt.axvline(cv, color='g'); # critical value\n",
    "plt.axvline(observed_diff, color='r'); # observed mean difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation test result\n",
    "It is very unlikely that the observed_diff value or greater appeared if there is no difference in the groups, so **there is a difference between the drug and the placebo groups**. We have sufficient evidence to reject the null hypothesis, the drug works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def tstatistic(sample1, sample2, alpha, one_tail):\n",
    "    '''\n",
    "    Calculate t-statistic for 2 samples\n",
    "    Are the two samples expected to have been drawn from the same population?\n",
    "    '''\n",
    "    # Calculate means\n",
    "    mean1, mean2 = np.mean(sample1), np.mean(sample2)\n",
    "    \n",
    "    # Calculate sample standard deviations\n",
    "    std1, std2 = np.std(sample1, ddof=1), np.std(sample2, ddof=1)\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    n1, n2 = len(sample1), len(sample2)\n",
    "    se1, se2 = std1/np.sqrt(n1), std2/np.sqrt(n2)\n",
    "\n",
    "    # Standard error on the difference between the samples\n",
    "    sed = np.sqrt(se1**2.0 + se2**2.0)\n",
    "    \n",
    "    # Calculate degrees of freedom\n",
    "    df = len(sample1) + len(sample2) - 2\n",
    "    \n",
    "    # Calculate the t statistic\n",
    "    t_stat = (mean1 - mean2) / sed\n",
    "    \n",
    "    # Calculate the critical value\n",
    "    if one_tail:\n",
    "        cv = stats.t.ppf(1.0 - alpha, df)\n",
    "    else:\n",
    "        cv = stats.t.ppf(1.0 - alpha/2, df) # 2-tailed\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p = (1.0 - stats.t.cdf(abs(t_stat), df)) * 2.0\n",
    "    \n",
    "    return t_stat, df, cv, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, df, cv, p = tstatistic(drug, placebo, alpha, one_tail=False)\n",
    "t, df, cv, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
